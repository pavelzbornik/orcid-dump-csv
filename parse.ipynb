{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lxml.etree \n",
    "import csv\n",
    "import tarfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:35<00:00, 278.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def getHeaderFromXSLT(xslt):\n",
    "    root=xslt.getroot()\n",
    "    \n",
    "    headers=[]\n",
    "\n",
    "    for item in root.findall('.//xsl:value-of',namespaces=root.nsmap):\n",
    "        #ignore variables\n",
    "        if (item.find('..').tag!='{http://www.w3.org/1999/XSL/Transform}variable'):\n",
    "            el = item.attrib['select'].replace('.//','').replace('@','').replace('normalize-space(translate(','').replace(\",'[¬]',''))\",'').replace('$','').replace('/','__')\n",
    "            if(el=='.'):\n",
    "                #select the parent of the tag in order ot get select attribute\n",
    "                el = item.find('..').attrib['select'].replace('.//','').replace('@','').replace('normalize-space(translate(','').replace(\",'[¬]',''))\",'').replace('$','').replace('/','__')\n",
    "            headers.append(el)\n",
    "    return headers\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def readTar(file:str):\n",
    "    with tarfile.open(file, \"r:gz\") as tar:\n",
    "        # Go over each member\n",
    "        for member in tar:\n",
    "            if '.xml' in member.name:\n",
    "                yield tar.extractfile(member).read()  \n",
    "\n",
    "def writeRows(writer,tree,header,xslt):\n",
    "    transform = lxml.etree.XSLT(xslt)\n",
    "    transformed=transform(tree)\n",
    "    lines=str(transformed).split('$end_line$')\n",
    "    for line in lines:\n",
    "        #write only if there are values in the line\n",
    "        if (len(header)<=len(line)):\n",
    "            writer.writerow(line.split('¬'))\n",
    "\n",
    "# open your tar.gz file\n",
    "\n",
    "file='ORCID_2021_10_summaries.tar.gz'\n",
    "\n",
    "\n",
    "outdir='data'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "xslt_files=[]\n",
    "headers=[]\n",
    "files=[]\n",
    "filenames=[]\n",
    "writers=[]\n",
    "\n",
    "outdir='data'\n",
    "\n",
    "for xslt_file in glob.glob('xslt/*.xsl'):\n",
    "    xslt=lxml.etree.parse(xslt_file)\n",
    "    xslt_files.append(xslt)\n",
    "    name=os.path.basename(xslt_file).replace('.xsl','')\n",
    "    filenames.append(name)\n",
    "    f=open(os.path.join(outdir, \"orcid_\"+name+'.csv'), \"w\", encoding=\"utf8\")\n",
    "    files.append(f)\n",
    "    headers.append(getHeaderFromXSLT(xslt))\n",
    "    writers.append(csv.writer(f, lineterminator=\"\\n\"))\n",
    "\n",
    "\n",
    "#write header row\n",
    "for i in range(0,len(files)):\n",
    "    writers[i].writerow(headers[i])\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "for xml in tqdm(itertools.islice(readTar(file), 10000),total=10000):\n",
    "#for xml in tqdm(readTar(file),total=12000000):\n",
    "    # Extract member\n",
    "    tree = lxml.etree.fromstring(xml)\n",
    "    for i in range(0,len(files)):\n",
    "        writeRows(writers[i],tree,headers[i],xslt_files[i])\n",
    "        \n",
    "\n",
    "for file in files:\n",
    "    file.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error reading file 'xslt/profile.xsl': failed to load external entity \"xslt/profile.xsl\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\orcid\\parse.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/orcid/parse.ipynb#ch0000011?line=55'>56</a>\u001b[0m od_writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(od, lineterminator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/orcid/parse.ipynb#ch0000011?line=57'>58</a>\u001b[0m \u001b[39m#load XSLT defintions\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/orcid/parse.ipynb#ch0000011?line=58'>59</a>\u001b[0m xslt_profile\u001b[39m=\u001b[39mlxml\u001b[39m.\u001b[39;49metree\u001b[39m.\u001b[39;49mparse(\u001b[39m'\u001b[39;49m\u001b[39mxslt/profile.xsl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/orcid/parse.ipynb#ch0000011?line=59'>60</a>\u001b[0m xslt_external_identifier\u001b[39m=\u001b[39mlxml\u001b[39m.\u001b[39metree\u001b[39m.\u001b[39mparse(\u001b[39m'\u001b[39m\u001b[39mxslt/external-identifier.xsl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/orcid/parse.ipynb#ch0000011?line=60'>61</a>\u001b[0m xslt_researcher_url\u001b[39m=\u001b[39mlxml\u001b[39m.\u001b[39metree\u001b[39m.\u001b[39mparse(\u001b[39m'\u001b[39m\u001b[39mxslt/researcher-url.xsl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32msrc\\lxml\\etree.pyx:3538\u001b[0m, in \u001b[0;36mlxml.etree.parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:1876\u001b[0m, in \u001b[0;36mlxml.etree._parseDocument\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:1902\u001b[0m, in \u001b[0;36mlxml.etree._parseDocumentFromURL\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:1805\u001b[0m, in \u001b[0;36mlxml.etree._parseDocFromFile\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:1177\u001b[0m, in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFile\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:615\u001b[0m, in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:725\u001b[0m, in \u001b[0;36mlxml.etree._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\parser.pxi:652\u001b[0m, in \u001b[0;36mlxml.etree._raiseParseError\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Error reading file 'xslt/profile.xsl': failed to load external entity \"xslt/profile.xsl\""
     ]
    }
   ],
   "source": [
    "\n",
    "# open your tar.gz file\n",
    "\n",
    "file='ORCID_2021_10_summaries.tar.gz'\n",
    "\n",
    "def getHeaderFromXSLT(xslt):\n",
    "    root=xslt.getroot()\n",
    "    \n",
    "    headers=[]\n",
    "\n",
    "    for item in root.findall('.//xsl:value-of',namespaces=root.nsmap):\n",
    "        #ignore variables\n",
    "        if (item.find('..').tag!='{http://www.w3.org/1999/XSL/Transform}variable'):\n",
    "            el = item.attrib['select'].replace('.//','').replace('@','').replace('normalize-space(translate(','').replace(\",'[¬]',''))\",'').replace('$','').replace('/','__')\n",
    "            if(el=='.'):\n",
    "                #select the parent of the tag in order ot get select attribute\n",
    "                el = item.find('..').attrib['select'].replace('.//','').replace('@','').replace('normalize-space(translate(','').replace(\",'[¬]',''))\",'').replace('$','').replace('/','__')\n",
    "            headers.append(el)\n",
    "    return headers\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def readTar(file:str):\n",
    "    with tarfile.open(file, \"r:gz\") as tar:\n",
    "        # Go over each member\n",
    "        for member in tar:\n",
    "            if '.xml' in member.name:\n",
    "                yield tar.extractfile(member).read()  \n",
    "\n",
    "def writeRows(writer,tree,header,xslt):\n",
    "    transform = lxml.etree.XSLT(xslt)\n",
    "    transformed=transform(tree)\n",
    "    lines=str(transformed).split('$end_line$')\n",
    "    for line in lines:\n",
    "        #write only if there are values in the line\n",
    "        if (len(header)!=len(line)):\n",
    "            writer.writerow(line.split('¬'))\n",
    "\n",
    "outdir='data'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\n",
    "    os.path.join(outdir, \"orcid_profiles.csv\"), \"w\", encoding=\"utf8\") as op, open(\n",
    "        os.path.join(outdir, \"orcid_external-identifiers.csv\"), \"w\", encoding=\"utf8\") as oei, open(\n",
    "            os.path.join(outdir, \"orcid_researcher-url.csv\"), \"w\", encoding=\"utf8\") as oru, open(\n",
    "                os.path.join(outdir, \"orcid_distinctions.csv\"), \"w\", encoding=\"utf8\") as od:\n",
    "        \n",
    "    op_writer = csv.writer(op, lineterminator=\"\\n\")\n",
    "    oei_writer = csv.writer(oei, lineterminator=\"\\n\")\n",
    "    oru_writer = csv.writer(oru, lineterminator=\"\\n\")\n",
    "    od_writer = csv.writer(od, lineterminator=\"\\n\")\n",
    "\n",
    "    #load XSLT defintions\n",
    "    xslt_profile=lxml.etree.parse('xslt/profile.xsl')\n",
    "    xslt_external_identifier=lxml.etree.parse('xslt/external-identifier.xsl')\n",
    "    xslt_researcher_url=lxml.etree.parse('xslt/researcher-url.xsl')\n",
    "    xslt_distinctions=lxml.etree.parse('xslt/distinctions.xsl')\n",
    "\n",
    "    #get CSV headers from XSLT\n",
    "    header_profile =getHeaderFromXSLT(xslt_profile)\n",
    "    header_identifiers=getHeaderFromXSLT(xslt_external_identifier)\n",
    "    header_researcher_url=getHeaderFromXSLT(xslt_researcher_url)\n",
    "    header_distinctions=getHeaderFromXSLT(xslt_distinctions)\n",
    "\n",
    "    #write header row\n",
    "    op_writer.writerow(header_profile)\n",
    "    oei_writer.writerow(header_identifiers)\n",
    "    oru_writer.writerow(header_researcher_url)\n",
    "    od_writer.writerow(header_distinctions)\n",
    "    import itertools\n",
    "\n",
    "    for xml in tqdm(itertools.islice(readTar(file), 10000),total=10000):\n",
    "    #for xml in tqdm(readTar(file),total=12000000):\n",
    "        # Extract member\n",
    "        tree = lxml.etree.fromstring(xml)\n",
    "        writeRows(op_writer,tree,header_profile,xslt_profile)\n",
    "        writeRows(oei_writer,tree,header_identifiers,xslt_external_identifier)\n",
    "        writeRows(oru_writer,tree,header_researcher_url,xslt_researcher_url)\n",
    "        writeRows(od_writer,tree,header_distinctions,xslt_distinctions)\n",
    "        \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0231656221878b8d95870d43fe2a6c265f262b31a475f1165baedc82f408ead7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
